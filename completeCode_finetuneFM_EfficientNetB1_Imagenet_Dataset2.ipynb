{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHVVp7FgHDeqkDQfctVhuN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samadkhani/ImageRecommendation/blob/main/completeCode_finetuneFM_EfficientNetB1_Imagenet_Dataset2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LlTWsXb2BJk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import numpy\n",
        "import glob\n",
        "from keras.preprocessing.image import load_img\n",
        "import warnings\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras import optimizers\n",
        "#from keras import optimizers\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy import io\n",
        "import scipy.io as spio\n",
        "\n",
        "\n",
        "\n",
        "num_classes = 8\n",
        "Img_size = 200\n",
        "input_shape = (Img_size, Img_size, 3)\n",
        "read_images = []\n",
        "y_train = []\n",
        "\n",
        "class_lable = 0\n",
        "folders = glob.glob('/content/gdrive/MyDrive/Emotion_DataSet1/amusement')\n",
        "imagenames_list = []\n",
        "num =0\n",
        "print(folders)\n",
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.jpg'):\n",
        "        imagenames_list.append(f)\n",
        "        num =num+1\n",
        "        #print(num)\n",
        "\n",
        "num2 =0\n",
        "for image in imagenames_list:\n",
        "    # load the image via load_img function\n",
        "    img = load_img(image)\n",
        "    # details about the image printed below\n",
        "    print(img.size)\n",
        "    resized_image = img.resize((Img_size, Img_size))\n",
        "\n",
        "    # convert the given image into  numpy array\n",
        "    img_numpy_array = img_to_array(resized_image)\n",
        "    print(\"Image is converted and NumPy array information :\")\n",
        "    # <class 'numpy.ndarray'>\n",
        "    print(type(img_numpy_array))\n",
        "    # type: float32\n",
        "    print(\"type:\", img_numpy_array.dtype)\n",
        "    # shape: (200, 400, 3)\n",
        "    print(\"shape:\", img_numpy_array.shape)\n",
        "\n",
        "    read_images.append(img_numpy_array)\n",
        "    y_train.append(class_lable)\n",
        "    num2 = num2 + 1\n",
        "    print(num2)\n",
        "\n",
        "#######\n",
        "class_lable = 1\n",
        "folders = glob.glob('/content/gdrive/MyDrive/Emotion_DataSet1/anger')\n",
        "imagenames_list = []\n",
        "num =0\n",
        "print(folders)\n",
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.jpg'):\n",
        "        imagenames_list.append(f)\n",
        "        num =num+1\n",
        "        #print(num)\n",
        "\n",
        "num2 =0\n",
        "for image in imagenames_list:\n",
        "    # load the image via load_img function\n",
        "    img = load_img(image)\n",
        "    # details about the image printed below\n",
        "    print(img.size)\n",
        "    resized_image = img.resize((Img_size, Img_size))\n",
        "\n",
        "    # convert the given image into  numpy array\n",
        "    img_numpy_array = img_to_array(resized_image)\n",
        "    print(\"Image is converted and NumPy array information :\")\n",
        "    # <class 'numpy.ndarray'>\n",
        "    print(type(img_numpy_array))\n",
        "    # type: float32\n",
        "    print(\"type:\", img_numpy_array.dtype)\n",
        "    # shape: (200, 400, 3)\n",
        "    print(\"shape:\", img_numpy_array.shape)\n",
        "\n",
        "    read_images.append(img_numpy_array)\n",
        "\n",
        "    y_train.append(class_lable)\n",
        "    num2 = num2 + 1\n",
        "    print(num2)\n",
        "\n",
        "\n",
        "######\n",
        "class_lable = 2\n",
        "folders = glob.glob('/content/gdrive/MyDrive/Emotion_DataSet1/awe')\n",
        "imagenames_list = []\n",
        "num =0\n",
        "print(folders)\n",
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.jpg'):\n",
        "        imagenames_list.append(f)\n",
        "        num =num+1\n",
        "        #print(num)\n",
        "\n",
        "num2 =0\n",
        "for image in imagenames_list:\n",
        "    # load the image via load_img function\n",
        "    img = load_img(image)\n",
        "    # details about the image printed below\n",
        "    print(img.size)\n",
        "    resized_image = img.resize((Img_size, Img_size))\n",
        "\n",
        "    # convert the given image into  numpy array\n",
        "    img_numpy_array = img_to_array(resized_image)\n",
        "    print(\"Image is converted and NumPy array information :\")\n",
        "    # <class 'numpy.ndarray'>\n",
        "    print(type(img_numpy_array))\n",
        "    # type: float32\n",
        "    print(\"type:\", img_numpy_array.dtype)\n",
        "    # shape: (200, 400, 3)\n",
        "    print(\"shape:\", img_numpy_array.shape)\n",
        "\n",
        "    read_images.append(img_numpy_array)\n",
        "    y_train.append(class_lable)\n",
        "    num2 = num2 + 1\n",
        "    print(num2)\n",
        "\n",
        "\n",
        "######\n",
        "class_lable = 3\n",
        "folders = glob.glob('/content/gdrive/MyDrive/Emotion_DataSet1/contentment')\n",
        "imagenames_list = []\n",
        "num =0\n",
        "print(folders)\n",
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.jpg'):\n",
        "        imagenames_list.append(f)\n",
        "        num =num+1\n",
        "        #print(num)\n",
        "\n",
        "num2 =0\n",
        "for image in imagenames_list:\n",
        "    # load the image via load_img function\n",
        "    img = load_img(image)\n",
        "    # details about the image printed below\n",
        "    print(img.size)\n",
        "    resized_image = img.resize((Img_size, Img_size))\n",
        "\n",
        "    # convert the given image into  numpy array\n",
        "    img_numpy_array = img_to_array(resized_image)\n",
        "    print(\"Image is converted and NumPy array information :\")\n",
        "    # <class 'numpy.ndarray'>\n",
        "    print(type(img_numpy_array))\n",
        "    # type: float32\n",
        "    print(\"type:\", img_numpy_array.dtype)\n",
        "    # shape: (200, 400, 3)\n",
        "    print(\"shape:\", img_numpy_array.shape)\n",
        "\n",
        "    read_images.append(img_numpy_array)\n",
        "\n",
        "    y_train.append(class_lable)\n",
        "    num2 = num2 + 1\n",
        "    print(num2)\n",
        "\n",
        "\n",
        "######\n",
        "class_lable = 4\n",
        "folders = glob.glob('/content/gdrive/MyDrive/Emotion_DataSet1/fear')\n",
        "imagenames_list = []\n",
        "num =0\n",
        "print(folders)\n",
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.jpg'):\n",
        "        imagenames_list.append(f)\n",
        "        num =num+1\n",
        "        #print(num)\n",
        "\n",
        "num2 =0\n",
        "for image in imagenames_list:\n",
        "    # load the image via load_img function\n",
        "    img = load_img(image)\n",
        "    # details about the image printed below\n",
        "    print(img.size)\n",
        "    resized_image = img.resize((Img_size, Img_size))\n",
        "\n",
        "    # convert the given image into  numpy array\n",
        "    img_numpy_array = img_to_array(resized_image)\n",
        "    print(\"Image is converted and NumPy array information :\")\n",
        "    # <class 'numpy.ndarray'>\n",
        "    print(type(img_numpy_array))\n",
        "    # type: float32\n",
        "    print(\"type:\", img_numpy_array.dtype)\n",
        "    # shape: (200, 400, 3)\n",
        "    print(\"shape:\", img_numpy_array.shape)\n",
        "\n",
        "    read_images.append(img_numpy_array)\n",
        "    y_train.append(class_lable)\n",
        "    num2 = num2 + 1\n",
        "    print(num2)\n",
        "\n",
        "\n",
        "######\n",
        "class_lable = 5\n",
        "folders = glob.glob('/content/gdrive/MyDrive/Emotion_DataSet1/sadness')\n",
        "imagenames_list = []\n",
        "num =0\n",
        "print(folders)\n",
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.jpg'):\n",
        "        imagenames_list.append(f)\n",
        "        num =num+1\n",
        "        #print(num)\n",
        "\n",
        "num2 =0\n",
        "for image in imagenames_list:\n",
        "    # load the image via load_img function\n",
        "    img = load_img(image)\n",
        "    # details about the image printed below\n",
        "    print(img.size)\n",
        "    resized_image = img.resize((Img_size, Img_size))\n",
        "\n",
        "    # convert the given image into  numpy array\n",
        "    img_numpy_array = img_to_array(resized_image)\n",
        "    print(\"Image is converted and NumPy array information :\")\n",
        "    # <class 'numpy.ndarray'>\n",
        "    print(type(img_numpy_array))\n",
        "    # type: float32\n",
        "    print(\"type:\", img_numpy_array.dtype)\n",
        "    # shape: (200, 400, 3)\n",
        "    print(\"shape:\", img_numpy_array.shape)\n",
        "\n",
        "    read_images.append(img_numpy_array)\n",
        "    y_train.append(class_lable)\n",
        "    num2 = num2 + 1\n",
        "    print(num2)\n",
        "\n",
        "\n",
        "######\n",
        "class_lable = 6\n",
        "folders = glob.glob('/content/gdrive/MyDrive/Emotion_DataSet1/disgust')\n",
        "imagenames_list = []\n",
        "num =0\n",
        "print(folders)\n",
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.jpg'):\n",
        "        imagenames_list.append(f)\n",
        "        num =num+1\n",
        "        #print(num)\n",
        "\n",
        "num2 =0\n",
        "for image in imagenames_list:\n",
        "    # load the image via load_img function\n",
        "    img = load_img(image)\n",
        "    # details about the image printed below\n",
        "    print(img.size)\n",
        "    resized_image = img.resize((Img_size, Img_size))\n",
        "\n",
        "    # convert the given image into  numpy array\n",
        "    img_numpy_array = img_to_array(resized_image)\n",
        "    print(\"Image is converted and NumPy array information :\")\n",
        "    # <class 'numpy.ndarray'>\n",
        "    print(type(img_numpy_array))\n",
        "    # type: float32\n",
        "    print(\"type:\", img_numpy_array.dtype)\n",
        "    # shape: (200, 400, 3)\n",
        "    print(\"shape:\", img_numpy_array.shape)\n",
        "\n",
        "    read_images.append(img_numpy_array)\n",
        "    y_train.append(class_lable)\n",
        "    num2 = num2 + 1\n",
        "    print(num2)\n",
        "\n",
        "\n",
        "######\n",
        "class_lable = 7\n",
        "folders = glob.glob('/content/gdrive/MyDrive/Emotion_DataSet1/excitement')\n",
        "imagenames_list = []\n",
        "num =0\n",
        "print(folders)\n",
        "for folder in folders:\n",
        "    for f in glob.glob(folder+'/*.jpg'):\n",
        "        imagenames_list.append(f)\n",
        "        num =num+1\n",
        "        #print(num)\n",
        "\n",
        "num2 =0\n",
        "for image in imagenames_list:\n",
        "    # load the image via load_img function\n",
        "    img = load_img(image)\n",
        "    # details about the image printed below\n",
        "    print(img.size)\n",
        "    resized_image = img.resize((Img_size, Img_size))\n",
        "\n",
        "    # convert the given image into  numpy array\n",
        "    img_numpy_array = img_to_array(resized_image)\n",
        "    print(\"Image is converted and NumPy array information :\")\n",
        "    # <class 'numpy.ndarray'>\n",
        "    print(type(img_numpy_array))\n",
        "    # type: float32\n",
        "    print(\"type:\", img_numpy_array.dtype)\n",
        "    # shape: (200, 400, 3)\n",
        "    print(\"shape:\", img_numpy_array.shape)\n",
        "\n",
        "    read_images.append(img_numpy_array)\n",
        "    y_train.append(class_lable)\n",
        "    num2 = num2 + 1\n",
        "    print(num2)\n",
        "\n",
        "\n",
        "xData = np.array(read_images)\n",
        "xData.shape\n",
        "\n",
        "y_Data = np.array(y_train)\n",
        "y_Data.shape\n",
        "\n",
        "y_Data = keras.utils.to_categorical(y_Data, num_classes)\n",
        "y_Data.shape\n",
        "\n",
        "# split into train test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_testVal, y_train, y_testVal = train_test_split(xData, y_Data, test_size=0.2, random_state=40)\n",
        "print(X_train.shape, X_testVal.shape, y_train.shape, y_testVal.shape)\n",
        "\n",
        "\n",
        "X_test, X_Val, y_test, y_Val = train_test_split(X_testVal, y_testVal, test_size=0.25, random_state=40)\n",
        "print(X_test.shape, X_Val.shape, y_test.shape, y_Val.shape)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "IMG_SIZE = Img_size\n",
        "from tensorflow.keras.applications import EfficientNetB1\n",
        "\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "conv_base = EfficientNetB1(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "#Model = EfficientNetB3(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet')\n",
        "\n",
        "conv_base.summary()\n",
        "\n",
        "from keras.models import Model\n",
        "model_base = Model(inputs=conv_base.inputs, outputs=conv_base.layers[320].output)\n",
        "model_base.summary()\n",
        "\n",
        "\n",
        "print('This is the number of trainable weights '\n",
        "      'before freezing the conv base:', len(model_base.trainable_weights))\n",
        "\n",
        "# Freeze the pretrained weights\n",
        "model_base.trainable = False\n",
        "\n",
        "\n",
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(model_base.trainable_weights))\n",
        "\n",
        "\n",
        "model_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in model_base.layers:\n",
        "    if layer.name == 'block6e_project_conv':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "          layer.trainable = True\n",
        "          print(\"okkkkkkkkk\")\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "\n",
        "\n",
        "print('This is the number of trainable weights '\n",
        "      'after uuuuunfreezing the conv base:', len(model_base.trainable_weights))\n",
        "\n",
        "\n",
        "\n",
        "# Rebuild top\n",
        "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model_base.output)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "top_dropout_rate = 0.2\n",
        "x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "#x = layers.Dropout(0.5, name=\"top_dropout_2\")(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "batch_size = 30\n",
        "num_epochs = 20\n",
        "\n",
        "def run_experiment(model):\n",
        "    optimizer = optimizers.RMSprop(lr=2e-4)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.CategoricalCrossentropy(\n",
        "            from_logits=True, label_smoothing=0.1\n",
        "        ),\n",
        "        metrics=[\n",
        "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_data= (X_Val, y_Val),\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history , model\n",
        "\n",
        "\n",
        "cct_model = model\n",
        "history , model= run_experiment(cct_model)\n",
        "\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "predict_X_test = model.predict(X_test)\n",
        "print(predict_X_test.shape)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), predict_X_test.argmax(axis=1))\n",
        "matrix\n",
        "\n",
        "\n",
        "\n",
        "# UserImage\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.activations import *\n",
        "import keras.backend as K\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def get_datatest():\n",
        "    X = []\n",
        "    y = []\n",
        "    k = 0\n",
        "\n",
        "    for j in os.listdir('/content/gdrive/My Drive/UserImages/'):\n",
        "      for i in os.listdir('/content/gdrive/My Drive/UserImages/'  + str(j) + '/'):\n",
        "        name = '/content/gdrive/My Drive/UserImages/'  + str(j) + '/'  + str(i)\n",
        "        print(name)\n",
        "        try :\n",
        "          img = Image.open(name)\n",
        "          k = k + 1\n",
        "          print(k)\n",
        "        except Exception:\n",
        "          continue\n",
        "        img = img.resize((Img_size, Img_size)).convert(\"RGB\")\n",
        "        X.append(np.array(img))\n",
        "\n",
        "    X = np.array(X)\n",
        "    return X , k\n",
        "\n",
        "UserImages , k = get_datatest()\n",
        "print(UserImages.shape)\n",
        "\n",
        "\n",
        "predict_UserImages = model.predict(UserImages)\n",
        "print(predict_UserImages.shape)\n",
        "\n",
        "\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks\n",
        "io.savemat(\"predict_FMfinetunEfficientNetB1_Data2.mat\", {\"array\": predict_UserImages})\n",
        "\n",
        "\n"
      ]
    }
  ]
}